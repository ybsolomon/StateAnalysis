{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning for New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import maup\n",
    "\n",
    "maup.progress.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary files from the redistricting hub:\n",
    "\n",
    "- **ny_pl2020_vtd**: https://redistrictingdatahub.org/dataset/new-york-vtd-pl-94171-2020/\n",
    "- **ny_2022_gen_prec**: https://redistrictingdatahub.org/dataset/new-york-2022-general-election-precinct-level-results-and-boundaries/\n",
    "- **ny_cong_adopted_2022**: https://redistrictingdatahub.org/dataset/2022-new-york-congressional-districts-plan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = gpd.read_file(\"./ny_pl2020_vtd/ny_pl2020_vtd.shp\")\n",
    "election_df = gpd.read_file(\"./ny_2022_gen_prec/ny_2022_gen_prec.shp\")\n",
    "cong_df = gpd.read_file(\"./ny_cong_adopted_2022/CON22_June_03_2022.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_cpy = election_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's clean up the column names from ```election_df```, and remove the ones we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G22ATGDJAM Letitia James-:-Attorney General-:--:-DEM                   \n",
    "# G22ATGOWRI Write-In Votes                                                            \n",
    "# G22ATGRHEN Michael Henry-:-Attorney General-:--:-REP                   \n",
    "# G22COMDDIN Thomas P DiNapoli-:-State Comptroller-:--:-DEM              \n",
    "# G22COMOWRI Write-In Votes                                                            \n",
    "# G22COMRROD Paul Rodriguez-:-State Comptroller-:--:-REP                 \n",
    "# G22GOVDHOC Kathy C Hochul-:-Governor-:--:-DEM                          \n",
    "# G22GOVOWRI Write-In Votes                                                            \n",
    "# G22GOVRZEL Lee Zeldin-:-Governor-:--:-REP                              \n",
    "# G22USSDSCH Charles E. Schumer-:-U.S. Senate-:--:-DEM                   \n",
    "# G22USSLSAR Diane Sare-:-U.S. Senate-:--:-LAR                           \n",
    "# G22USSOWRI Write-In Votes                                                            \n",
    "# G22USSRPIN Joe Pinion-:-U.S. Senate-:--:-REP      \n",
    "\n",
    "election_cpy.rename(columns={\n",
    "    \"G22ATGDJAM\": \"G22ATGD\",\n",
    "    \"G22ATGRHEN\": \"G22ATGR\",\n",
    "    \"G22COMDDIN\": \"G22COMD\",\n",
    "    \"G22COMRROD\": \"G22COMR\",\n",
    "    \"G22GOVDHOC\": \"G22GOVD\",\n",
    "    \"G22GOVRZEL\": \"G22GOVR\",\n",
    "    \"G22USSDSCH\": \"G22USSD\",\n",
    "    \"G22USSRPIN\": \"G22USSR\"\n",
    "}, inplace=True)\n",
    "\n",
    "election_cpy = election_cpy[[\n",
    "    \"G22ATGD\", \"G22ATGR\", \"G22COMD\", \"G22COMR\",\n",
    "    \"G22GOVD\", \"G22GOVR\", \"G22USSD\", \"G22USSR\",\n",
    "    \"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to make sure we only have the election columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G22ATGD', 'G22ATGR', 'G22COMD', 'G22COMR', 'G22GOVD', 'G22GOVR',\n",
       "       'G22USSD', 'G22USSR', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_cpy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the column from ```cong_df``` that gives us the unique district identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>398240.168961</td>\n",
       "      <td>4.747143e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((742169.526 4532898.369, 736334.250 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>207672.858852</td>\n",
       "      <td>1.482939e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((693595.108 4531758.179, 693510.421 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>146813.371952</td>\n",
       "      <td>6.453502e+08</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((632044.962 4535980.849, 632198.219 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100444.291013</td>\n",
       "      <td>4.891851e+08</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((622128.271 4510545.013, 622090.862 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113036.578196</td>\n",
       "      <td>2.913121e+08</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((603301.333 4509330.502, 603368.523 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID     Shape_Leng    Shape_Area  DISTRICT  \\\n",
       "0         1  398240.168961  4.747143e+09         1   \n",
       "1         2  207672.858852  1.482939e+09         2   \n",
       "2         3  146813.371952  6.453502e+08         3   \n",
       "3         4  100444.291013  4.891851e+08         4   \n",
       "4         5  113036.578196  2.913121e+08         5   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((742169.526 4532898.369, 736334.250 4...  \n",
       "1  POLYGON ((693595.108 4531758.179, 693510.421 4...  \n",
       "2  POLYGON ((632044.962 4535980.849, 632198.219 4...  \n",
       "3  POLYGON ((622128.271 4510545.013, 622090.862 4...  \n",
       "4  POLYGON ((603301.333 4509330.502, 603368.523 4...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *We'll save column DISTRICT for later*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_col_name = \"DISTRICT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we need to align the precincts from the 2018 data with the 2020 census data, but first we must make sure the CRS values match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4269\n",
      "EPSG:26918\n",
      "EPSG:4269\n"
     ]
    }
   ],
   "source": [
    "print(population_df.crs)\n",
    "print(cong_df.crs)\n",
    "print(election_cpy.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looks like the CRS values don't match. This will cause issues while calling ```maup.assign()```, so let's update them to match `population_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4269\n",
      "EPSG:4269\n"
     ]
    }
   ],
   "source": [
    "election_cpy.to_crs(population_df.crs, inplace=True)\n",
    "cong_df.to_crs(population_df.crs, inplace=True)\n",
    "\n",
    "print(election_cpy.crs)\n",
    "print(cong_df.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great! Now lets go ahead and get our mappings between the census and election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13963/13963 [00:08<00:00, 1612.37it/s]\n",
      "  9%|▉         | 1242/13963 [00:02<00:33, 380.55it/s]/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      " 92%|█████████▏| 12812/13963 [00:35<00:16, 70.85it/s] /Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      " 97%|█████████▋| 13554/13963 [00:37<00:01, 306.80it/s]/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/set_operations.py:131: RuntimeWarning: divide by zero encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "100%|██████████| 13963/13963 [00:39<00:00, 356.93it/s]\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "vtds_to_precincts_assignment = maup.assign(population_df.geometry, election_cpy.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A lot of these columns names don't make sense, but we'll copy the population data columns from `population_df` into `election_df` for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13963/13963 [00:18<00:00, 774.71it/s] \n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/repair.py:331: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  overlaps = inters[inters.area > 0].make_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2190 overlaps.\n",
      "There are 5683 holes.\n",
      "There are some invalid geometries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maup.doctor(election_cpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:95: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = shapely.wkb.loads(\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:125: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = make_valid(geometries_df[\"geometry\"][i])\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:129: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = unary_union([x for x in geometries_df[\"geometry\"][i].geoms if x.geom_type in (\"Polygon\", \"MultiPolygon\")])\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:149: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = make_valid(geometries_df[\"geometry\"][i])\n",
      "/Users/y.solomon/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:151: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = unary_union([x for x in geometries_df[\"geometry\"][i].geoms if x.geom_type in (\"Polygon\", \"MultiPolygon\")])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n"
     ]
    },
    {
     "ename": "GEOSException",
     "evalue": "TopologyException: Iterated noding failed to converge after 6 iterations (near 554193 4.61327e+06)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGEOSException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m election_repair \u001b[38;5;241m=\u001b[39m election_cpy\u001b[38;5;241m.\u001b[39mto_crs(election_cpy\u001b[38;5;241m.\u001b[39mestimate_utm_crs())\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmaup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_repair\u001b[49m\u001b[43m(\u001b[49m\u001b[43melection_repair\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:160\u001b[0m, in \u001b[0;36msmart_repair\u001b[0;34m(geometries_df, snapped, snap_precision, fill_gaps, fill_gaps_threshold, disconnection_threshold, nest_within_regions, min_rook_length)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnapping all geometries to a grid with precision 10^(\u001b[39m\u001b[38;5;124m\"\u001b[39m, snap_magnitude, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) to avoid GEOS errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Construct data about overlaps of all orders, plus holes.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m overlap_tower, holes_df \u001b[38;5;241m=\u001b[39m \u001b[43mbuilding_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometries_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest_within_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregions_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Use data from the overlap tower to rebuild geometries with no overlaps.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# If nest_within_regions is not None, resolve overlaps and fill holes (if applicable)\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# for each region separately.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nest_within_regions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/maup/smart_repair.py:363\u001b[0m, in \u001b[0;36mbuilding_blocks\u001b[0;34m(geometries_df, nest_within_regions)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m geom\u001b[38;5;241m.\u001b[39mgeom_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiLineString\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    362\u001b[0m         boundaries_exploded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(geom\u001b[38;5;241m.\u001b[39mgeoms)\n\u001b[0;32m--> 363\u001b[0m boundaries_union \u001b[38;5;241m=\u001b[39m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultiLineString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboundaries_exploded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Create a geodataframe with all the pieces created by overlaps of all orders,\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# together with a set for each piece consisting of the polygons that created the overlap.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m pieces_df \u001b[38;5;241m=\u001b[39m GeoDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolygon indices\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    368\u001b[0m                          geometry\u001b[38;5;241m=\u001b[39mGeoSeries(\u001b[38;5;28mlist\u001b[39m(polygonize(boundaries_union))),\n\u001b[1;32m    369\u001b[0m                          crs\u001b[38;5;241m=\u001b[39mgeometries_df\u001b[38;5;241m.\u001b[39mcrs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[1;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gerry/lib/python3.12/site-packages/shapely/constructive.py:613\u001b[0m, in \u001b[0;36mnode\u001b[0;34m(geometry, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;129m@multithreading_enabled\u001b[39m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnode\u001b[39m(geometry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    585\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m    Returns the fully noded version of the linear input as MultiLineString.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    <MULTILINESTRING EMPTY>\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mGEOSException\u001b[0m: TopologyException: Iterated noding failed to converge after 6 iterations (near 554193 4.61327e+06)"
     ]
    }
   ],
   "source": [
    "election_repair = election_cpy.to_crs(election_cpy.estimate_utm_crs())\n",
    "maup.smart_repair(election_repair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_column_names = ['P0020001', 'P0020002', 'P0020005', 'P0020006',\n",
    "                    'P0020007', 'P0020008', 'P0020009', 'P0020010']\n",
    "\n",
    "vap_column_names = ['P0040001', 'P0040002', 'P0040005', 'P0040006',\n",
    "                    'P0040007', 'P0040008', 'P0040009', 'P0040010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P0020001</th>\n",
       "      <th>P0020002</th>\n",
       "      <th>P0020005</th>\n",
       "      <th>P0020006</th>\n",
       "      <th>P0020007</th>\n",
       "      <th>P0020008</th>\n",
       "      <th>P0020009</th>\n",
       "      <th>P0020010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>586.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>998.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P0020001  P0020002  P0020005  P0020006  P0020007  P0020008  P0020009  \\\n",
       "0     160.0      21.0     100.0      20.0       4.0       8.0       0.0   \n",
       "1     586.0      66.0     265.0     209.0       0.0      26.0       0.0   \n",
       "2     998.0     187.0     367.0     314.0       1.0      66.0       4.0   \n",
       "3    1092.0     231.0     317.0     355.0       6.0      61.0       0.0   \n",
       "4      33.0       6.0      12.0       1.0       0.0       7.0       0.0   \n",
       "\n",
       "   P0020010  \n",
       "0       0.0  \n",
       "1       4.0  \n",
       "2       4.0  \n",
       "3       5.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_df[pop_column_names] = population_df[pop_column_names].groupby(vtds_to_precincts_assignment).sum()\n",
    "\n",
    "election_df[pop_column_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to check to see if we lost any of the population in the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population_df:\n",
      "P0020001    20201249\n",
      "P0020002     3948032\n",
      "P0020005    10598907\n",
      "P0020006     2759022\n",
      "P0020007       54908\n",
      "P0020008     1916329\n",
      "P0020009        6097\n",
      "P0020010      197107\n",
      "dtype: int64\n",
      "election_df:\n",
      "P0020001    20201218.0\n",
      "P0020002     3948015.0\n",
      "P0020005    10598906.0\n",
      "P0020006     2759019.0\n",
      "P0020007       54908.0\n",
      "P0020008     1916327.0\n",
      "P0020009        6097.0\n",
      "P0020010      197107.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('population_df:')\n",
    "print(population_df[pop_column_names].sum())\n",
    "\n",
    "print('election_df:')\n",
    "print(election_df[pop_column_names].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now comes the mapping between 2018 and 2020 data using `maup.prorate`. This will give us population weights that we can use to reassign the district population to the 2020 districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2018 = population_df[\"P0040001\"] / vtds_to_precincts_assignment.map(population_df[\"P0040001\"].groupby(vtds_to_precincts_assignment).sum())\n",
    "weights2018 = weights2018.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P0020001</th>\n",
       "      <th>P0020002</th>\n",
       "      <th>P0020005</th>\n",
       "      <th>P0020006</th>\n",
       "      <th>P0020007</th>\n",
       "      <th>P0020008</th>\n",
       "      <th>P0020009</th>\n",
       "      <th>P0020010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>617.740727</td>\n",
       "      <td>69.604589</td>\n",
       "      <td>458.048948</td>\n",
       "      <td>41.327725</td>\n",
       "      <td>3.987763</td>\n",
       "      <td>22.29522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.537667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2477.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3393.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1141.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1497.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1349.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      P0020001    P0020002     P0020005     P0020006   P0020007  P0020008  \\\n",
       "0   617.740727   69.604589   458.048948    41.327725   3.987763  22.29522   \n",
       "1  2477.000000  142.000000  2143.000000    11.000000  11.000000  47.00000   \n",
       "2  3393.000000  612.000000  1517.000000  1141.000000  21.000000  18.00000   \n",
       "3  1490.000000  134.000000  1050.000000   154.000000   1.000000  23.00000   \n",
       "4  1497.000000   45.000000  1349.000000     6.000000   4.000000   4.00000   \n",
       "\n",
       "   P0020009   P0020010  \n",
       "0       0.0   2.537667  \n",
       "1       0.0  12.000000  \n",
       "2       1.0  14.000000  \n",
       "3       0.0   9.000000  \n",
       "4       0.0   3.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prorated2018 = maup.prorate(vtds_to_precincts_assignment, election_df[pop_column_names], weights2018)\n",
    "\n",
    "prorated2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we'll store the prorated election columns from `election_df` in `population_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_cols = [\"G18SEND\", \"G18SENR\", \"G18GOVD\", \"G18GOVR\", \"G18COMD\", \"G18COMR\", \"G18ATGD\", \"G18ATGR\"]\n",
    "\n",
    "population_df[election_cols] = prorated2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One more check to make sure we didn't lose anyone in the proration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P0020001    20201249\n",
      "P0020002     3948032\n",
      "P0020005    10598907\n",
      "P0020006     2759022\n",
      "P0020007       54908\n",
      "P0020008     1916329\n",
      "P0020009        6097\n",
      "P0020010      197107\n",
      "dtype: int64\n",
      "P0020001    20201249.0\n",
      "P0020002     3948032.0\n",
      "P0020005    10598907.0\n",
      "P0020006     2759022.0\n",
      "P0020007       54908.0\n",
      "P0020008     1916329.0\n",
      "P0020009        6097.0\n",
      "P0020010      197107.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(population_df[pop_column_names].sum())\n",
    "print(election_df[pop_column_names].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfect! Now that we know we haven't lost anyone, let's make sure `maup.doctor()` runs without any holes in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14191/14191 [00:07<00:00, 1900.54it/s]\n",
      "/Users/rishab/Library/Python/3.9/lib/python/site-packages/maup/repair.py:331: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  overlaps = inters[inters.area > 0].make_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maup.doctor(population_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This step will feel familiar, we'll call `maup.assign()` to map the congressional districts from `cong_df` to the precincts in `population_df`\n",
    "#### Once we have this assignment, we'll add a new `CD` column to `population_df` with the district that the given precinct falls under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 148.49it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 36.49it/s]\n",
      "/Users/rishab/Library/Python/3.9/lib/python/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/Users/rishab/Library/Python/3.9/lib/python/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/rishab/Library/Python/3.9/lib/python/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "precincts_to_districts_assignment = maup.assign(population_df.geometry, cong_df.geometry)\n",
    "population_df[\"CD\"] = precincts_to_districts_assignment\n",
    "\n",
    "for precinct_index in range(len(population_df)):\n",
    "    population_df.at[precinct_index, \"CD\"] = int(cong_df.at[population_df.at[precinct_index, \"CD\"], district_col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Almost done! Now it's time to rename those columns from before so that we know what they stand for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEFP20', 'COUNTYFP20', 'VTDST20', 'GEOID20', 'VTDI20', 'NAME20',\n",
       "       'NAMELSAD20', 'LSAD20', 'MTFCC20', 'FUNCSTAT20',\n",
       "       ...\n",
       "       'geometry', 'G18SEND', 'G18SENR', 'G18GOVD', 'G18GOVR', 'G18COMD',\n",
       "       'G18COMR', 'G18ATGD', 'G18ATGR', 'CD'],\n",
       "      dtype='object', length=357)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {'P0020001': 'TOTPOP', 'P0020002': 'HISP', 'P0020005': 'NH_WHITE', 'P0020006': 'NH_BLACK', 'P0020007': 'NH_AMIN',\n",
    "                    'P0020008': 'NH_ASIAN', 'P0020009': 'NH_NHPI', 'P0020010': 'NH_OTHER',\n",
    "                    'P0040001': 'VAP', 'P0040002': 'HVAP', 'P0040005': 'WVAP', 'P0040006': 'BVAP', 'P0040007': 'AMINVAP',\n",
    "                                        'P0040008': 'ASIANVAP', 'P0040009': 'NHPIVAP', 'P0040010': 'OTHERVAP'}\n",
    "\n",
    "population_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "population_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, our last step is to save our dataframe into a shapefile we can use for future analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.to_file(\"./NY/NY.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gerry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
